# ğŸ¤– Advanced RAG Systems

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.50.0-FF4B4B.svg)](https://streamlit.io)
[![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)](https://langchain.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ Project Overview

This project demonstrates the implementation of two production-ready **Retrieval Augmented Generation (RAG)** systems using state-of-the-art technologies including LangChain, FAISS vector store, and Google's Gemini API. The systems showcase advanced document retrieval, semantic search, and AI-powered question answering capabilities.

### ğŸ¯ Key Features

- **Dual RAG Applications**: Medical Q&A and Policy Compliance systems
- **Advanced Embeddings**: Sentence Transformers (all-MiniLM-L6-v2) for semantic understanding
- **Efficient Vector Search**: FAISS for lightning-fast similarity search
- **Modern UI**: Beautiful Streamlit interfaces with custom styling
- **Production-Ready**: Comprehensive error handling and logging
- **Scalable Architecture**: Modular design for easy extension

## Project Structure

```
â”œâ”€â”€ data/                   # Dataset storage (CSV and PDF)
â”œâ”€â”€ src/                    # Source code for RAG pipelines
â”‚   â”œâ”€â”€ compliance.py       # Task 2 logic
â”‚   â”œâ”€â”€ data_loader.py      # Document loading utilities
â”‚   â”œâ”€â”€ embedding.py        # Embedding generation
â”‚   â”œâ”€â”€ search.py           # Task 1 RAG logic
â”‚   â””â”€â”€ vectorstore.py      # FAISS vector store management
â”œâ”€â”€ app.py                  # (Deprecated)
â”œâ”€â”€ compliance_rules.json   # Rules for Task 2
â”œâ”€â”€ evaluate.py             # Evaluation script for Task 1
â”œâ”€â”€ main_app.py             # Main Streamlit entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ streamlit_app.py        # Task 1 UI
â””â”€â”€ task2_app.py            # Task 2 UI
```

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interface (Streamlit)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Medical QA     â”‚              â”‚   Compliance     â”‚   â”‚
â”‚  â”‚   (Task 1)       â”‚              â”‚   Checker        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                                 â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  RAGSearch       â”‚              â”‚ ComplianceCheckerâ”‚   â”‚
â”‚  â”‚  (search.py)     â”‚              â”‚ (compliance.py)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                                 â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜             â”‚
â”‚  â”‚      FAISS Vector Store               â”‚               â”‚
â”‚  â”‚      (vectorstore.py)                 â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚           â”‚                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   Sentence Transformers Embeddings    â”‚               â”‚
â”‚  â”‚   (embedding.py)                      â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚      Google Gemini API               â”‚               â”‚
â”‚  â”‚      (LLM Response Generation)        â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Technical Stack

| Component | Technology | Purpose |
|-----------|-----------|----------|
| **LLM** | Google Gemini 2.0 Flash | Natural language generation |
| **Embeddings** | Sentence Transformers (all-MiniLM-L6-v2) | Text vectorization |
| **Vector DB** | FAISS | Similarity search & retrieval |
| **Framework** | LangChain | RAG orchestration |
| **UI** | Streamlit | Web interface |
| **Data Processing** | Pandas, PyPDF | Document loading & processing |

## ğŸ“¦ Prerequisites

1.  **Python 3.10+** - Required for latest dependencies
2.  **Google Gemini API Key** - Free tier available at [Google AI Studio](https://aistudio.google.com/)
3.  **4GB+ RAM** - For vector store operations
4.  **2GB+ Storage** - For datasets and embeddings

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone <repository-url>
cd RAG
```

### 2. Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

**Key Dependencies:**
- `langchain` - RAG framework
- `langchain-community` - Document loaders
- `google-generativeai` - Gemini API
- `sentence-transformers` - Embeddings
- `faiss-cpu` - Vector store
- `streamlit` - UI framework
- `pandas` - Data processing

### 4. Configure Environment
Create a `.env` file in the root directory:
```env
GOOGLE_API_KEY=your_api_key_here
```

**Getting your API key:**
1. Visit [Google AI Studio](https://aistudio.google.com/)
2. Sign in with your Google account
3. Click "Get API Key"
4. Copy and paste into `.env` file

### 5. Prepare Data
Ensure the following files are in the `data/` directory:
- `Task1_data.csv` - Medical transcriptions dataset
- `Task2_data.pdf` - Policy document

### 6. Run the Application
```bash
streamlit run main_app.py
```
The app will open at `http://localhost:8501`

## ğŸ¥ Task 1: Medical RAG QA System

### Overview
An intelligent medical assistant that provides evidence-based answers to clinical questions by retrieving relevant information from a database of 5,000+ medical transcriptions.

### Features
- âœ… **Semantic Search**: Uses embeddings to find contextually similar medical records
- âœ… **Context-Aware Responses**: Retrieves top-K relevant documents before generating answers
- âœ… **Source Attribution**: Shows which medical records were used to generate the answer
- âœ… **Safety First**: Includes disclaimers and advises consulting medical professionals

### Dataset
- **Source**: [Medical Transcriptions - Kaggle](https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions)
- **Size**: 4,999 clinical documents
- **Content**: Medical histories, procedures, diagnoses across 40+ specialties
- **Processing**: Chunked into 29,894 segments for optimal retrieval

### Running the Application
```bash
streamlit run main_app.py
# Select "ğŸ¥ Medical QA" from the sidebar
```

### Sample Questions
- "What are the symptoms of allergic rhinitis?"
- "Describe the procedure for laparoscopic gastric bypass"
- "What is a 2-D Echocardiogram used for?"
- "What medications are used for high cholesterol?"

### Evaluation
Run comprehensive evaluation on 30 medical queries:
```bash
python evaluate.py
```

**Output:** `evaluation_results.csv` containing:
- Query text
- Generated response
- Response time
- Source documents used

### Performance Metrics
- **Average Response Time**: ~2-3 seconds
- **Vector Store Size**: 29,894 chunks
- **Embedding Dimension**: 384
- **Top-K Retrieval**: 5 documents

## ğŸ›¡ï¸ Task 2: Policy Compliance Checker

### Overview
An automated compliance auditing system that evaluates company policies against predefined security and governance rules, providing evidence-based compliance reports.

### Features
- âœ… **Automated Auditing**: Evaluates 15 compliance rules automatically
- âœ… **Evidence-Based Results**: Provides direct quotes from policy documents
- âœ… **Remediation Suggestions**: AI-generated recommendations for non-compliant policies
- âœ… **Interactive Q&A**: Chat interface for policy exploration
- âœ… **Compliance Dashboard**: Visual metrics and downloadable reports

### Dataset
- **Source**: [CUAD - Atticus Project](https://www.atticusprojectai.org/cuad)
- **Format**: PDF policy documents
- **Processing**: Extracted and chunked into 52 segments

### Compliance Rules
The system checks against 15 rules across categories:

| Category | Examples |
|----------|----------|
| **Data Security** | Encryption standards, data protection |
| **Access Control** | MFA requirements, authentication |
| **Password Policy** | Complexity, rotation frequency |
| **Remote Work** | VPN usage, secure connections |
| **Incident Response** | Reporting procedures, timelines |
| **Vendor Management** | NDA requirements, third-party access |

### Running the Application
```bash
streamlit run main_app.py
# Select "ğŸ›¡ï¸ Compliance Checker" from the sidebar
```

### Usage

#### 1. Automated Audit
1. Click "ğŸš€ Run Compliance Check"
2. View compliance metrics dashboard
3. Review detailed findings table
4. Download CSV report

#### 2. Policy Q&A
1. Type a question or click sample questions
2. Get AI-powered answers with source references
3. View retrieved context for verification

### Sample Questions
- "What is the policy on remote work?"
- "How often should passwords be changed?"
- "Are personal devices allowed for work?"
- "What is the security incident reporting procedure?"

### Output Format
Compliance report includes:
- **Rule ID**: Unique identifier
- **Category**: Policy domain
- **Status**: Compliant / Non-Compliant / Missing
- **Evidence**: Direct quotes from policy
- **Remediation**: Suggested fixes
- **Severity**: High / Medium / Low

## ğŸ“Š Project Statistics

### Task 1: Medical QA
- **Documents**: 4,999 medical transcriptions
- **Chunks**: 29,894 text segments
- **Vector Store**: 11.4 MB
- **Specialties**: 40+ medical fields
- **Evaluation Queries**: 30

### Task 2: Compliance
- **Documents**: 11 PDF pages
- **Chunks**: 52 text segments
- **Rules**: 15 compliance checks
- **Categories**: 10 policy domains
- **Severity Levels**: 3 (High/Medium/Low)

## ğŸ¨ UI Features

### Design Elements
- **Gradient Headers**: Eye-catching color schemes
- **Responsive Layout**: Optimized for all screen sizes
- **Interactive Components**: Buttons, expanders, metrics
- **Custom Styling**: CSS-enhanced aesthetics
- **Sample Questions**: Quick-start templates
- **Progress Indicators**: Real-time feedback

### User Experience
- **Intuitive Navigation**: Clear sidebar menu
- **Fast Loading**: Cached resources for speed
- **Error Handling**: Graceful failure messages
- **Download Options**: Export results as CSV
- **Source Attribution**: Transparency in AI responses

## ğŸ”¬ Technical Implementation

### Document Processing Pipeline
```python
1. Load Documents (CSV/PDF/TXT/etc.)
   â†“
2. Split into Chunks (RecursiveCharacterTextSplitter)
   â†“
3. Generate Embeddings (Sentence Transformers)
   â†“
4. Store in FAISS (Vector Database)
   â†“
5. Query & Retrieve (Semantic Search)
   â†“
6. Generate Response (Gemini API)
```

### Key Components

**`src/data_loader.py`**
- Supports multiple formats: PDF, CSV, TXT, DOCX, JSON
- Automatic encoding detection
- Metadata preservation

**`src/embedding.py`**
- Sentence Transformers integration
- Configurable chunk sizes
- Batch processing for efficiency

**`src/vectorstore.py`**
- FAISS index management
- Persistent storage
- Fast similarity search

**`src/search.py`** (Task 1)
- RAG pipeline orchestration
- Context retrieval
- Gemini integration

**`src/compliance.py`** (Task 2)
- Rule-based evaluation
- Evidence extraction
- Remediation generation

## ğŸ§ª Testing & Evaluation

### Task 1 Evaluation
```bash
python evaluate.py
```

Tests 30 diverse medical queries across:
- Symptoms & diagnosis
- Procedures & treatments
- Medical equipment
- Chronic conditions

### Metrics Collected
- Response accuracy
- Retrieval relevance
- Generation time
- Source quality

## ğŸ“ File Structure Explained

```
RAG/
â”‚
â”œâ”€â”€ data/                          # Dataset storage
â”‚   â”œâ”€â”€ Task1_data.csv            # Medical transcriptions
â”‚   â””â”€â”€ Task2_data.pdf            # Policy documents
â”‚
â”œâ”€â”€ src/                           # Core application logic
â”‚   â”œâ”€â”€ data_loader.py            # Multi-format document loader
â”‚   â”œâ”€â”€ embedding.py              # Text chunking & embeddings
â”‚   â”œâ”€â”€ vectorstore.py            # FAISS vector database
â”‚   â”œâ”€â”€ search.py                 # Task 1 RAG pipeline
â”‚   â””â”€â”€ compliance.py             # Task 2 compliance engine
â”‚
â”œâ”€â”€ faiss_store/                   # Task 1 vector store
â”‚   â”œâ”€â”€ faiss.index               # FAISS index file
â”‚   â””â”€â”€ metadata.pkl              # Document metadata
â”‚
â”œâ”€â”€ faiss_store_policy/            # Task 2 vector store
â”‚   â”œâ”€â”€ faiss.index
â”‚   â””â”€â”€ metadata.pkl
â”‚
â”œâ”€â”€ main_app.py                    # Main Streamlit entry point
â”œâ”€â”€ streamlit_app.py              # Task 1 UI
â”œâ”€â”€ task2_app.py                  # Task 2 UI
â”œâ”€â”€ evaluate.py                    # Task 1 evaluation script
â”œâ”€â”€ compliance_rules.json          # Task 2 rule definitions
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env                          # Environment variables (API keys)
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Deployment Guide

### Streamlit Cloud (Recommended)
1. Push code to GitHub
2. Visit [share.streamlit.io](https://share.streamlit.io)
3. Connect your repository
4. Add `GOOGLE_API_KEY` to secrets
5. Deploy!

### Hugging Face Spaces
1. Create new Space on [huggingface.co](https://huggingface.co)
2. Select Streamlit SDK
3. Upload code files
4. Configure secrets
5. Launch

### Local Network Deployment
```bash
streamlit run main_app.py --server.port 8080 --server.address 0.0.0.0
```

## ğŸ› ï¸ Troubleshooting

### Common Issues

**Issue**: `GOOGLE_API_KEY not found`
- **Solution**: Ensure `.env` file exists with valid API key

**Issue**: `No module named 'faiss'`
- **Solution**: `pip install faiss-cpu`

**Issue**: Vector store takes too long to build
- **Solution**: Reduce chunk size or use pre-built store

**Issue**: Out of memory errors
- **Solution**: Process documents in batches

## ğŸ“š Additional Resources

- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)
- [FAISS GitHub](https://github.com/facebookresearch/faiss)
- [Gemini API Docs](https://ai.google.dev/docs)
- [Streamlit Docs](https://docs.streamlit.io)

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## âœ‰ï¸ Contact

For questions or feedback, please open an issue on GitHub.

---

**Built with â¤ï¸ using LangChain, FAISS, and Google Gemini**
